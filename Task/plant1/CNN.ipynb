{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa488e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling1d        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m5\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)          â”‚         \u001b[38;5;34m6,176\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling1d        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m2,112\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m65\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,377</span> (36.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,377\u001b[0m (36.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,377</span> (36.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,377\u001b[0m (36.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ========================================\n",
    "# CNN-Only Solar Power Forecasting\n",
    "# ========================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# ============================\n",
    "# 1. Load dataset\n",
    "# ============================\n",
    "df = pd.read_csv(r\"C:\\Users\\User\\Desktop\\solar_code\\Task\\plant1\\Plant1_Merged_Final.csv\")\n",
    "\n",
    "# Ensure datetime format\n",
    "df['DATE_TIME'] = pd.to_datetime(df['DATE_TIME'])\n",
    "\n",
    "# Time features\n",
    "df['hour'] = df['DATE_TIME'].dt.hour\n",
    "df['minute'] = df['DATE_TIME'].dt.minute\n",
    "df['time_fraction'] = df['hour'] + df['minute']/60\n",
    "\n",
    "# Cyclical encoding\n",
    "df['sin_time'] = np.sin(2 * np.pi * df['time_fraction'] / 24)\n",
    "df['cos_time'] = np.cos(2 * np.pi * df['time_fraction'] / 24)\n",
    "\n",
    "# Drop unused columns\n",
    "df = df.drop(columns=['hour','minute','time_fraction','DATE_TIME'])\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=['AC_POWER'])\n",
    "y = df['AC_POWER'].values   # raw watts\n",
    "\n",
    "# ============================\n",
    "# 2. Create sliding windows\n",
    "# ============================\n",
    "sequence_length = 6\n",
    "X_seq, y_seq = [], []\n",
    "\n",
    "for i in range(len(X) - sequence_length):\n",
    "    X_seq.append(X.iloc[i:i+sequence_length].values)\n",
    "    y_seq.append(y[i+sequence_length])\n",
    "\n",
    "X_seq = np.array(X_seq)\n",
    "y_seq = np.array(y_seq)\n",
    "\n",
    "# ============================\n",
    "# 3. Scale ONLY X\n",
    "# ============================\n",
    "scaler_X = MinMaxScaler()\n",
    "X_flat = X_seq.reshape(-1, X_seq.shape[-1])\n",
    "X_scaled = scaler_X.fit_transform(X_flat).reshape(X_seq.shape)\n",
    "\n",
    "# y stays raw\n",
    "y_raw = y_seq.reshape(-1,1)\n",
    "\n",
    "# ============================\n",
    "# 4. Train/Test split\n",
    "# ============================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_raw, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 5. CNN Model (Only CNN)\n",
    "# ============================\n",
    "timesteps = X_scaled.shape[1]\n",
    "n_features = X_scaled.shape[2]\n",
    "\n",
    "inputs = Input(shape=(timesteps, n_features))\n",
    "x = layers.Conv1D(64, 3, activation='relu', padding=\"causal\")(inputs)\n",
    "x = layers.Conv1D(32, 3, activation='relu', padding=\"causal\")(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "\n",
    "cnn_model = Model(inputs, outputs)\n",
    "cnn_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14a25e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 117231784.0000 - mae: 6733.2139 - val_loss: 94294144.0000 - val_mae: 6290.6523\n",
      "Epoch 2/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 58840868.0000 - mae: 5900.2524 - val_loss: 30277526.0000 - val_mae: 4871.6270\n",
      "Epoch 3/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 20960618.0000 - mae: 3829.0149 - val_loss: 16392832.0000 - val_mae: 3042.6228\n",
      "Epoch 4/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 12781813.0000 - mae: 2526.1748 - val_loss: 12447077.0000 - val_mae: 2268.3545\n",
      "Epoch 5/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 10140468.0000 - mae: 2056.4268 - val_loss: 10143941.0000 - val_mae: 1955.8978\n",
      "Epoch 6/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8612921.0000 - mae: 1805.6316 - val_loss: 8826906.0000 - val_mae: 1725.8558\n",
      "Epoch 7/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 7756548.0000 - mae: 1620.6602 - val_loss: 7864844.5000 - val_mae: 1585.0139\n",
      "Epoch 8/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 7254617.5000 - mae: 1529.6764 - val_loss: 7474572.0000 - val_mae: 1523.3058\n",
      "Epoch 9/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6952554.0000 - mae: 1477.3695 - val_loss: 7290139.5000 - val_mae: 1491.5211\n",
      "Epoch 10/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6917355.5000 - mae: 1470.7953 - val_loss: 7092575.0000 - val_mae: 1495.0560\n",
      "Epoch 11/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6779286.5000 - mae: 1447.7644 - val_loss: 6992024.5000 - val_mae: 1497.5350\n",
      "Epoch 12/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6791661.5000 - mae: 1463.0168 - val_loss: 6957511.0000 - val_mae: 1481.7253\n",
      "Epoch 13/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6718073.5000 - mae: 1445.8210 - val_loss: 7206833.0000 - val_mae: 1503.1404\n",
      "Epoch 14/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6754608.5000 - mae: 1467.6151 - val_loss: 7047340.0000 - val_mae: 1497.0264\n",
      "Epoch 15/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6696891.5000 - mae: 1446.0858 - val_loss: 6864680.5000 - val_mae: 1476.2626\n",
      "Epoch 16/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6732574.0000 - mae: 1453.3154 - val_loss: 6820439.0000 - val_mae: 1471.0642\n",
      "Epoch 17/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6656000.5000 - mae: 1438.0215 - val_loss: 6931162.0000 - val_mae: 1471.3068\n",
      "Epoch 18/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6671775.5000 - mae: 1442.1915 - val_loss: 6801178.5000 - val_mae: 1466.0851\n",
      "Epoch 19/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6712958.0000 - mae: 1449.4164 - val_loss: 6745449.5000 - val_mae: 1452.4103\n",
      "Epoch 20/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6639201.0000 - mae: 1435.5638 - val_loss: 6741049.0000 - val_mae: 1458.0077\n",
      "Epoch 21/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6626360.0000 - mae: 1432.6707 - val_loss: 6703716.5000 - val_mae: 1454.9799\n",
      "Epoch 22/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6593947.0000 - mae: 1439.2366 - val_loss: 6685719.5000 - val_mae: 1446.0555\n",
      "Epoch 23/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6554465.5000 - mae: 1427.1355 - val_loss: 6757617.0000 - val_mae: 1457.6887\n",
      "Epoch 24/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6565833.0000 - mae: 1440.5884 - val_loss: 6642731.0000 - val_mae: 1446.1333\n",
      "Epoch 25/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6604533.5000 - mae: 1441.6562 - val_loss: 6677997.0000 - val_mae: 1433.9700\n",
      "Epoch 26/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6579106.0000 - mae: 1421.5226 - val_loss: 6646434.0000 - val_mae: 1440.9409\n",
      "Epoch 27/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6543873.5000 - mae: 1416.0453 - val_loss: 6615943.5000 - val_mae: 1438.2126\n",
      "Epoch 28/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6469145.0000 - mae: 1422.9910 - val_loss: 6560679.5000 - val_mae: 1428.6400\n",
      "Epoch 29/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6434147.0000 - mae: 1405.0209 - val_loss: 6612041.0000 - val_mae: 1435.7372\n",
      "Epoch 30/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6452304.0000 - mae: 1412.7406 - val_loss: 6523181.5000 - val_mae: 1424.5784\n",
      "Epoch 31/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6460639.5000 - mae: 1411.6573 - val_loss: 6529438.5000 - val_mae: 1427.9968\n",
      "Epoch 32/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6429721.0000 - mae: 1415.3265 - val_loss: 6497219.5000 - val_mae: 1424.0175\n",
      "Epoch 33/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6482426.0000 - mae: 1414.5852 - val_loss: 6498202.0000 - val_mae: 1425.2140\n",
      "Epoch 34/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6474774.5000 - mae: 1413.7953 - val_loss: 6603038.0000 - val_mae: 1435.0662\n",
      "Epoch 35/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6429810.0000 - mae: 1407.3947 - val_loss: 6439927.5000 - val_mae: 1413.9661\n",
      "Epoch 36/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6412944.5000 - mae: 1407.7145 - val_loss: 6675563.5000 - val_mae: 1441.7299\n",
      "Epoch 37/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6381201.5000 - mae: 1404.0419 - val_loss: 6465851.5000 - val_mae: 1428.2966\n",
      "Epoch 38/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6393423.5000 - mae: 1407.1552 - val_loss: 6417201.0000 - val_mae: 1413.3668\n",
      "Epoch 39/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6336108.0000 - mae: 1394.8744 - val_loss: 6403767.5000 - val_mae: 1420.3069\n",
      "Epoch 40/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6382497.0000 - mae: 1410.3020 - val_loss: 6506854.5000 - val_mae: 1428.7697\n",
      "Epoch 41/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6379902.5000 - mae: 1398.5614 - val_loss: 6520171.5000 - val_mae: 1430.4169\n",
      "Epoch 42/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6334487.5000 - mae: 1397.8325 - val_loss: 6315735.5000 - val_mae: 1411.2212\n",
      "Epoch 43/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6345936.5000 - mae: 1410.6997 - val_loss: 6371366.5000 - val_mae: 1409.8850\n",
      "Epoch 44/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6418330.5000 - mae: 1400.4423 - val_loss: 6371808.5000 - val_mae: 1413.9901\n",
      "Epoch 45/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6275867.5000 - mae: 1386.7930 - val_loss: 6265157.0000 - val_mae: 1397.1399\n",
      "Epoch 46/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6265746.5000 - mae: 1387.8746 - val_loss: 6247584.0000 - val_mae: 1389.5751\n",
      "Epoch 47/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6256991.0000 - mae: 1393.9977 - val_loss: 6247241.5000 - val_mae: 1380.9952\n",
      "Epoch 48/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6247752.0000 - mae: 1384.4567 - val_loss: 6388105.5000 - val_mae: 1409.3439\n",
      "Epoch 49/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6294358.5000 - mae: 1390.9316 - val_loss: 6261129.0000 - val_mae: 1388.7605\n",
      "Epoch 50/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6210298.5000 - mae: 1379.8048 - val_loss: 6338092.5000 - val_mae: 1405.1868\n",
      "Epoch 51/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6189814.5000 - mae: 1375.3514 - val_loss: 6211827.0000 - val_mae: 1396.6558\n",
      "Epoch 52/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6170831.5000 - mae: 1376.6069 - val_loss: 6226826.0000 - val_mae: 1394.5803\n",
      "Epoch 53/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6141799.5000 - mae: 1376.1688 - val_loss: 6192929.0000 - val_mae: 1390.5031\n",
      "Epoch 54/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6108323.0000 - mae: 1370.3669 - val_loss: 6690390.5000 - val_mae: 1452.1318\n",
      "Epoch 55/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6214794.5000 - mae: 1393.0863 - val_loss: 6104322.5000 - val_mae: 1374.0582\n",
      "Epoch 56/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6067855.5000 - mae: 1354.5963 - val_loss: 6121949.0000 - val_mae: 1391.8132\n",
      "Epoch 57/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6208758.0000 - mae: 1389.6558 - val_loss: 6249912.0000 - val_mae: 1399.9520\n",
      "Epoch 58/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6121966.5000 - mae: 1367.3073 - val_loss: 6066758.0000 - val_mae: 1377.3951\n",
      "Epoch 59/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6166596.0000 - mae: 1374.9341 - val_loss: 6038930.0000 - val_mae: 1368.4209\n",
      "Epoch 60/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6027846.0000 - mae: 1359.1562 - val_loss: 6115845.0000 - val_mae: 1383.4835\n",
      "Epoch 61/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6014216.0000 - mae: 1357.4432 - val_loss: 6060363.5000 - val_mae: 1369.5557\n",
      "Epoch 62/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6009210.0000 - mae: 1361.7041 - val_loss: 6131942.5000 - val_mae: 1381.0620\n",
      "Epoch 63/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5981766.5000 - mae: 1346.0715 - val_loss: 6054312.5000 - val_mae: 1374.4199\n",
      "Epoch 64/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5951303.0000 - mae: 1357.1687 - val_loss: 5981315.0000 - val_mae: 1360.1909\n",
      "Epoch 65/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6011677.5000 - mae: 1352.7146 - val_loss: 6161832.0000 - val_mae: 1386.0594\n",
      "Epoch 66/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5941818.0000 - mae: 1348.9629 - val_loss: 5934051.5000 - val_mae: 1355.3707\n",
      "Epoch 67/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5954801.5000 - mae: 1341.2898 - val_loss: 5913305.0000 - val_mae: 1352.0339\n",
      "Epoch 68/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5957396.0000 - mae: 1341.3654 - val_loss: 5968969.5000 - val_mae: 1362.8849\n",
      "Epoch 69/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5920214.5000 - mae: 1350.8507 - val_loss: 5883016.0000 - val_mae: 1351.3904\n",
      "Epoch 70/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5863852.5000 - mae: 1333.4009 - val_loss: 5869850.5000 - val_mae: 1347.0289\n",
      "Epoch 71/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5871268.0000 - mae: 1338.7493 - val_loss: 5844848.0000 - val_mae: 1344.3365\n",
      "Epoch 72/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5839200.5000 - mae: 1337.0751 - val_loss: 5847438.5000 - val_mae: 1340.7637\n",
      "Epoch 73/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5814254.0000 - mae: 1336.0057 - val_loss: 5831781.5000 - val_mae: 1339.1960\n",
      "Epoch 74/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5842762.5000 - mae: 1332.0695 - val_loss: 5819305.0000 - val_mae: 1333.9700\n",
      "Epoch 75/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5801830.5000 - mae: 1322.7029 - val_loss: 5800287.5000 - val_mae: 1329.7656\n",
      "Epoch 76/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5771270.0000 - mae: 1317.2960 - val_loss: 5821640.5000 - val_mae: 1345.6162\n",
      "Epoch 77/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5784159.0000 - mae: 1328.0387 - val_loss: 5792307.0000 - val_mae: 1327.7648\n",
      "Epoch 78/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5748128.5000 - mae: 1316.8497 - val_loss: 6012870.5000 - val_mae: 1359.0229\n",
      "Epoch 79/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5787942.5000 - mae: 1321.1481 - val_loss: 5742766.5000 - val_mae: 1324.6624\n",
      "Epoch 80/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5761013.5000 - mae: 1327.3851 - val_loss: 5769267.5000 - val_mae: 1317.3545\n",
      "Epoch 81/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5778273.0000 - mae: 1321.1271 - val_loss: 5713504.0000 - val_mae: 1313.7887\n",
      "Epoch 82/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5691762.5000 - mae: 1315.9126 - val_loss: 5918969.0000 - val_mae: 1341.4191\n",
      "Epoch 83/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5728898.0000 - mae: 1314.0770 - val_loss: 5713907.5000 - val_mae: 1323.3269\n",
      "Epoch 84/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5694912.5000 - mae: 1312.3915 - val_loss: 5874514.5000 - val_mae: 1329.2965\n",
      "Epoch 85/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5630517.0000 - mae: 1304.9174 - val_loss: 5832736.0000 - val_mae: 1323.1317\n",
      "Epoch 86/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5600851.5000 - mae: 1291.9166 - val_loss: 5672806.0000 - val_mae: 1312.7396\n",
      "Epoch 87/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5620632.5000 - mae: 1292.2910 - val_loss: 5670710.0000 - val_mae: 1312.7596\n",
      "Epoch 88/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5588229.0000 - mae: 1296.4601 - val_loss: 5681604.0000 - val_mae: 1309.2029\n",
      "Epoch 89/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5584884.0000 - mae: 1293.8293 - val_loss: 5622577.5000 - val_mae: 1299.0472\n",
      "Epoch 90/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5557988.0000 - mae: 1279.7371 - val_loss: 5603408.5000 - val_mae: 1295.0273\n",
      "Epoch 91/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5542902.5000 - mae: 1289.0939 - val_loss: 5590421.0000 - val_mae: 1289.5100\n",
      "Epoch 92/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5600729.5000 - mae: 1286.3236 - val_loss: 5594810.0000 - val_mae: 1286.2583\n",
      "Epoch 93/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5503448.0000 - mae: 1276.4938 - val_loss: 5672841.0000 - val_mae: 1298.6989\n",
      "Epoch 94/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5555633.0000 - mae: 1287.7854 - val_loss: 5597479.0000 - val_mae: 1288.6364\n",
      "Epoch 95/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5542695.0000 - mae: 1282.3583 - val_loss: 5619695.5000 - val_mae: 1294.8994\n",
      "Epoch 96/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5490729.0000 - mae: 1276.4890 - val_loss: 5553168.0000 - val_mae: 1275.0403\n",
      "Epoch 97/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5543317.5000 - mae: 1278.8226 - val_loss: 5611432.5000 - val_mae: 1277.3719\n",
      "Epoch 98/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5445974.0000 - mae: 1263.7560 - val_loss: 5650948.5000 - val_mae: 1284.6382\n",
      "Epoch 99/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5410946.0000 - mae: 1256.8193 - val_loss: 5547055.5000 - val_mae: 1275.1090\n",
      "Epoch 100/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5487596.0000 - mae: 1268.4236 - val_loss: 5582735.5000 - val_mae: 1272.4839\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 6. Train CNN\n",
    "# ============================\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[es],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 7. Evaluate\n",
    "# ============================\n",
    "y_pred = cnn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "908e4e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š CNN-only MSE: 6030939.05\n",
      "ğŸ“Š CNN-only RMSE: 2455.80\n",
      "ğŸ“Š CNN-only RÂ²: 0.9155\n",
      "ğŸ“Š CNN-only MAE: 1318.31\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"ğŸ“Š CNN-only MSE: {mse:.2f}\")\n",
    "print(f\"ğŸ“Š CNN-only RMSE: {rmse:.2f}\")\n",
    "print(f\"ğŸ“Š CNN-only RÂ²: {r2:.4f}\")\n",
    "print(f\"ğŸ“Š CNN-only MAE: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4b555f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CNN-only model and scaler saved!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 10. Save CNN Model\n",
    "# ============================\n",
    "cnn_model.save(r\"C:\\Users\\User\\Desktop\\solar_code\\Task\\plant1\\cnn_model\\model.h5\", include_optimizer=False)\n",
    "joblib.dump(scaler_X, r\"C:\\Users\\User\\Desktop\\solar_code\\Task\\plant1\\cnn_model\\scaler_X.pkl\")\n",
    "print(\"âœ… CNN-only model and scaler saved!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "775526f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "ğŸ”® Predicted AC Power (Next 15 min): [[5763.205]]\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 1. Inference function\n",
    "# ============================\n",
    "def preprocess_input_for_inference(df_input, sequence_length=6):\n",
    "    \"\"\"\n",
    "    Preprocess the input data for inference.\n",
    "    df_input: DataFrame with columns [DATE_TIME, AMBIENT_TEMPERATURE, MODULE_TEMPERATURE, IRRADIATION]\n",
    "    sequence_length: The number of past time steps (e.g., 6 time steps for 90 minutes)\n",
    "    returns: Scaled input data ready for prediction\n",
    "    \"\"\"\n",
    "    # Ensure datetime format\n",
    "    df_input['DATE_TIME'] = pd.to_datetime(df_input['DATE_TIME'])\n",
    "\n",
    "    # Time features\n",
    "    df_input['hour'] = df_input['DATE_TIME'].dt.hour\n",
    "    df_input['minute'] = df_input['DATE_TIME'].dt.minute\n",
    "    df_input['time_fraction'] = df_input['hour'] + df_input['minute'] / 60.0\n",
    "\n",
    "    # Cyclical encoding\n",
    "    df_input['sin_time'] = np.sin(2 * np.pi * df_input['time_fraction'] / 24)\n",
    "    df_input['cos_time'] = np.cos(2 * np.pi * df_input['time_fraction'] / 24)\n",
    "\n",
    "    # Drop unused columns\n",
    "    df_input = df_input.drop(columns=['hour', 'minute', 'time_fraction', 'DATE_TIME'])\n",
    "\n",
    "    # Create sliding window\n",
    "    X_seq = []\n",
    "    for i in range(len(df_input) - sequence_length + 1):  # Fixed window creation\n",
    "        X_seq.append(df_input.iloc[i:i+sequence_length].values)\n",
    "\n",
    "    X_seq = np.array(X_seq)\n",
    "\n",
    "    # Scale the input data\n",
    "    X_flat = X_seq.reshape(-1, X_seq.shape[-1])\n",
    "    X_scaled = scaler_X.transform(X_flat).reshape(X_seq.shape)\n",
    "\n",
    "    return X_scaled\n",
    "\n",
    "# ============================\n",
    "# 2. Prediction function\n",
    "# ============================\n",
    "def predict_ac_power_for_inference(new_data):\n",
    "    \"\"\"\n",
    "    Predict the AC power for the next 15 minutes using the trained CNN model.\n",
    "    new_data: DataFrame with the latest time series data for prediction\n",
    "    returns: predicted AC power\n",
    "    \"\"\"\n",
    "    # Preprocess the input data\n",
    "    X_scaled = preprocess_input_for_inference(new_data)\n",
    "\n",
    "    # Predict using CNN model\n",
    "    y_pred = cnn_model.predict(X_scaled)\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "# ============================\n",
    "# 3. Example Usage\n",
    "# ============================\n",
    "# Provide at least 6 consecutive rows (for sliding window)\n",
    "\n",
    "sample_data = pd.DataFrame({\n",
    "    \"DATE_TIME\": [\n",
    "        \"2020-05-15 06:00:00\",\n",
    "        \"2020-05-15 06:15:00\",\n",
    "        \"2020-05-15 06:30:00\",\n",
    "        \"2020-05-15 06:45:00\",\n",
    "        \"2020-05-15 07:00:00\",\n",
    "        \"2020-05-15 07:15:00\",\n",
    "    ],\n",
    "    \"AMBIENT_TEMPERATURE\": [24.08, 24.01, 23.97, 24.21, 24.53, 24.82],\n",
    "    \"MODULE_TEMPERATURE\": [22.20, 22.35, 22.89, 24.44, 27.19, 28.88],\n",
    "    \"IRRADIATION\": [0.0058, 0.0223, 0.0494, 0.0954, 0.1419, 0.1547]\n",
    "})\n",
    "\n",
    "# Make prediction for the next 15 min of AC_POWER\n",
    "preds = predict_ac_power_for_inference(sample_data)\n",
    "print(\"ğŸ”® Predicted AC Power (Next 15 min):\", preds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
